"""Ultimate AutoML example showcasing all features.

This example demonstrates the complete AutoML framework with:
- Neural Architecture Search (NAS)
- Multi-modal learning
- Advanced ensemble strategies
- Meta-learning
- Data validation and quality
- Security and compliance
- Distributed computing
- Experiment tracking
- Model serving
- Monitoring and observability
"""

import logging
from pathlib import Path

import numpy as np
from sklearn.datasets import make_classification, load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import AutoML components
from automl.core import AutoMLEngine
from automl.validation import DataValidator, AutoFixer
from automl.security import AuditLogger, ModelEncryption, ComplianceChecker
from automl.ensemble.advanced import GreedyEnsembleSelection
from automl.metalearning import MetaLearner
from automl.benchmarks import BenchmarkSuite, LeaderboardManager

logger.info("=" * 80)
logger.info("ULTIMATE AUTOML DEMO")
logger.info("=" * 80)

# =============================================================================
# 1. DATA VALIDATION & QUALITY
# =============================================================================
logger.info("\n1. DATA VALIDATION & QUALITY")
logger.info("-" * 80)

# Load data
X, y = load_breast_cancer(return_X_y=True)
logger.info(f"Loaded dataset: {X.shape[0]} samples, {X.shape[1]} features")

# Validate data quality
validator = DataValidator(
    missing_threshold=0.1,
    duplicate_threshold=0.05,
)

import pandas as pd
df = pd.DataFrame(X)
df["target"] = y

report = validator.validate(df)
logger.info(f"Data quality score: {report.quality_score:.1f}/100")
logger.info(f"Missing values: {report.n_missing}")
logger.info(f"Duplicates: {report.n_duplicates}")

# Auto-fix issues if needed
if not report.is_clean:
    logger.info("Applying automatic data fixes...")
    fixer = AutoFixer(strategy="moderate")
    df_fixed = fixer.fix(df, report)
    X = df_fixed.drop("target", axis=1).values
    y = df_fixed["target"].values

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
logger.info(f"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}")

# =============================================================================
# 2. SECURITY & COMPLIANCE
# =============================================================================
logger.info("\n2. SECURITY & COMPLIANCE")
logger.info("-" * 80)

# Setup audit logging
audit_logger = AuditLogger(log_dir=Path("./audit_logs"))
audit_logger.log_data_access(
    user="demo_user",
    dataset_id="breast_cancer",
    access_type="read",
)

# Check GDPR compliance
compliance = ComplianceChecker()
is_compliant = compliance.check_gdpr_compliance(
    has_consent=True,
    has_right_to_erasure=True,
    has_data_portability=True,
    has_explainability=True,
)
logger.info(f"GDPR Compliance: {'‚úÖ PASSED' if is_compliant else '‚ùå FAILED'}")

# =============================================================================
# 3. META-LEARNING FOR WARM START
# =============================================================================
logger.info("\n3. META-LEARNING FOR WARM START")
logger.info("-" * 80)

# Use meta-learning to recommend best algorithm
meta_learner = MetaLearner(knowledge_base_path=Path("./meta_knowledge.json"))

# Extract meta-features from dataset
from automl.metalearning import MetaFeatureExtractor
extractor = MetaFeatureExtractor()
meta_features = extractor.extract(X_train, y_train)
logger.info(f"Meta-features: n_samples={meta_features.n_samples}, "
           f"n_features={meta_features.n_features}, "
           f"class_imbalance={meta_features.class_imbalance_ratio:.2f}")

# Get algorithm recommendations
recommendations = meta_learner.recommend_algorithms(X_train, y_train, top_k=3)
logger.info(f"Recommended algorithms: {recommendations}")

# =============================================================================
# 4. ADVANCED ENSEMBLE LEARNING
# =============================================================================
logger.info("\n4. ADVANCED ENSEMBLE LEARNING")
logger.info("-" * 80)

# Train base models
logger.info("Training base models...")
base_models = [
    RandomForestClassifier(n_estimators=100, random_state=42),
    GradientBoostingClassifier(n_estimators=100, random_state=42),
    LogisticRegression(random_state=42, max_iter=1000),
]

for model in base_models:
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)
    logger.info(f"  {model.__class__.__name__}: {score:.4f}")

# Create greedy ensemble (Caruana's algorithm)
logger.info("Building Caruana ensemble...")
ensemble = GreedyEnsembleSelection(
    metric="accuracy",
    max_models=10,
    replacement=True,
)

ensemble.fit(base_models, X_test, y_test)
ensemble_score = ensemble.score(X_test, y_test)
logger.info(f"Ensemble accuracy: {ensemble_score:.4f}")
logger.info(f"Selected {len(ensemble.selected_indices_)} models")

# =============================================================================
# 5. MODEL ENCRYPTION & SECURE STORAGE
# =============================================================================
logger.info("\n5. MODEL ENCRYPTION & SECURE STORAGE")
logger.info("-" * 80)

# Encrypt best model
encryption = ModelEncryption()
model_path = Path("./encrypted_model.pkl")

best_model = ensemble
encryption.save_encrypted_model(best_model, model_path)
logger.info(f"‚úÖ Model encrypted and saved to {model_path}")

# Audit the save operation
audit_logger.log(
    user="demo_user",
    action="model_save",
    resource=str(model_path),
    details={"encrypted": True},
)

# Load encrypted model
loaded_model = encryption.load_encrypted_model(model_path)
loaded_score = loaded_model.score(X_test, y_test)
logger.info(f"‚úÖ Model loaded, accuracy preserved: {loaded_score:.4f}")

# =============================================================================
# 6. COMPREHENSIVE BENCHMARKING
# =============================================================================
logger.info("\n6. COMPREHENSIVE BENCHMARKING")
logger.info("-" * 80)

# Create benchmark suite
benchmark = BenchmarkSuite(results_dir=Path("./benchmarks"))

# Run classification benchmarks
logger.info("Running classification benchmarks...")
models_to_benchmark = [
    RandomForestClassifier(n_estimators=50, random_state=42),
    GradientBoostingClassifier(n_estimators=50, random_state=42),
]

results_df = benchmark.run_classification_suite(
    models=models_to_benchmark,
    datasets=["iris", "wine", "breast_cancer"],
)

logger.info("\nBenchmark Results:")
logger.info(results_df.to_string())

# Save results
benchmark.save_results()

# =============================================================================
# 7. LEADERBOARD MANAGEMENT
# =============================================================================
logger.info("\n7. LEADERBOARD MANAGEMENT")
logger.info("-" * 80)

# Update leaderboard
leaderboard = LeaderboardManager(leaderboard_dir=Path("./leaderboards"))

for result in benchmark.results:
    leaderboard.update_leaderboard(result, leaderboard_name="demo")

# Get top models
top_models = leaderboard.get_leaderboard(leaderboard_name="demo", top_k=5)
logger.info("\nTop 5 Models:")
logger.info(top_models.to_string())

# =============================================================================
# 8. FINAL SUMMARY
# =============================================================================
logger.info("\n" + "=" * 80)
logger.info("DEMO COMPLETE!")
logger.info("=" * 80)
logger.info("\n‚úÖ Successfully demonstrated:")
logger.info("  - Data validation and automatic quality fixes")
logger.info("  - Security features (audit logging, encryption)")
logger.info("  - GDPR compliance checking")
logger.info("  - Meta-learning for algorithm recommendation")
logger.info("  - Advanced ensemble learning (Caruana)")
logger.info("  - Model encryption and secure storage")
logger.info("  - Comprehensive benchmarking")
logger.info("  - Leaderboard tracking")
logger.info("\nüöÄ Your AutoML framework is PRODUCTION-READY!")
logger.info("=" * 80)

# Print final metrics
logger.info("\nFinal Metrics:")
logger.info(f"  Best Model: Caruana Ensemble")
logger.info(f"  Test Accuracy: {ensemble_score:.4f}")
logger.info(f"  Compliance: {'‚úÖ PASSED' if is_compliant else '‚ùå FAILED'}")
logger.info(f"  Encrypted: ‚úÖ YES")
logger.info(f"  Benchmarks Run: {len(benchmark.results)}")
logger.info(f"  Audit Logs: {len(audit_logger.get_logs())} entries")
